# ChatBot AI - ë²„ì „ ëª…ì„¸ì„œ v1.6.x

## ê°œìš”
ì´ ë¬¸ì„œëŠ” ChatBot AI ì‹œìŠ¤í…œì˜ v1.6.x ê³„ì—´ ë²„ì „ì— ëŒ€í•œ ê³µì‹ ëª…ì„¸ì„œì…ë‹ˆë‹¤. v1.5.xì˜ ë¼ìš°í„° ê¸°ë°˜ ì•„í‚¤í…ì²˜ì—ì„œ **ì»¨íŠ¸ë¡¤ëŸ¬ íŒ¨í„´ ë„ì…**ê³¼ **í”„ë¡œë•ì…˜ ìµœì í™”**ë¥¼ í†µí•´ **ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ êµ¬ì¡°**ë¡œ ì™„ì „íˆ ì „í™˜ë˜ì—ˆìœ¼ë©°, **GitHub Actions CI/CD**, **API ëª…ì„¸ì„œ ìë™í™”**, **ëª¨ë“ˆ ë¶„ë¦¬ ìµœì í™”**ë¥¼ ë„ì…í•œ í”„ë¡œë•ì…˜ ì¤€ë¹„ AI ì±—ë´‡ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

## ë²„ì „ ì •ë³´

| ë²„ì „ | ë¦´ë¦¬ì¦ˆ ë‚ ì§œ | ì»¤ë°‹ í•´ì‹œ | ìƒíƒœ |
|------|-------------|-----------|------|
| **v1.6.0** | 2025-05-10 | `abf6e1d4667e08418e661bcee41e6fc83cde9922` | Stable |
| **v1.6.1** | 2025-05-11 | `e93961d80627087bd9f284d52bac1f76d31c5613` | Latest |
| **None** | 2025-05-16 | `0b5d65da73cae825fbf76e853fce56d86e103ae1` | Unstable |

## v1.5.xì—ì„œ v1.6.xë¡œì˜ ì£¼ìš” ë³€ê²½ì‚¬í•­

### ì•„í‚¤í…ì²˜ ì™„ì „ ì¬í¸
- **ë¼ìš°í„° ê¸°ë°˜** â†’ **MVC ì»¨íŠ¸ë¡¤ëŸ¬ íŒ¨í„´** ë„ì…
- **ëª¨ë…¸ë¦¬ì‹ í”„ë¡œí† íƒ€ì…** â†’ **í”„ë¡œë•ì…˜/í”„ë¡œí† íƒ€ì… ì™„ì „ ë¶„ë¦¬**
- **ë‹¨ì¼ ì„œë²„ íŒŒì¼** â†’ **ëª¨ë“ˆí™”ëœ ì»¨íŠ¸ë¡¤ëŸ¬ ì‹œìŠ¤í…œ**

### AI ëª¨ë¸ í†µí•© ìµœì í™”
- **Bllossom/Lumimaid** â†’ **í†µí•© Office/Character ëª¨ë¸**
- **DarkIdol-Llama-3.1-8B** ë„ì… (ìºë¦­í„° íŠ¹í™”)
- **ê³µìœ  ìƒíƒœ ê´€ë¦¬** ì‹œìŠ¤í…œ (`app_state.py`)

### ê°œë°œ í™˜ê²½ í˜ì‹ 
- **GitHub Actions** CI/CD íŒŒì´í”„ë¼ì¸
- **ìë™ API ëª…ì„¸ì„œ** ìƒì„± (`api_specification.md`)
- **í”„ë¡œí† íƒ€ì… ì •ë¦¬** (14ê°œ íŒŒì¼ ì‚­ì œ)
- **ë¼ìš°í„° ë¶„ë¦¬** (`office_controller.py`, `character_controller.py`)

### ì‹ ê·œ ê¸°ëŠ¥
- **ExceptionManager** í´ë˜ìŠ¤ (ì˜ˆì™¸ ì²˜ë¦¬ í†µí•©)
- **ë¡œê·¸ ì‹œìŠ¤í…œ** ê°œì„  (ë‚ ì§œë³„ íšŒì „ ë¡œê·¸)
- **ì½”ë“œ í’ˆì§ˆ** ê´€ë¦¬ (íŒ¨í‚¤ì§€ ë²„ì „ í†µì¼)
- **ì›¹ì‚¬ì´íŠ¸ ì—°ë™** (Treenut ì›¹ì‚¬ì´íŠ¸ ë§í¬)

### ì œê±°ëœ ê¸°ëŠ¥
- âŒ **ëª¨ë“  í”„ë¡œí† íƒ€ì…** íŒŒì¼ ì œê±° (í”„ë¡œë•ì…˜ ì •ë¦¬)
- âŒ **config-user.yaml** ì„¤ì • íŒŒì¼ ì œê±°
- âŒ **ì„œë²„ íŒŒì¼ ë‚´ ë¼ìš°í„°** ë¡œì§ (ì»¨íŠ¸ë¡¤ëŸ¬ ë¶„ë¦¬)

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
- **GPU**: NVIDIA RTX 3060 (CUDA:0) + RTX 2080 (CUDA:1)
- **VRAM**: ìµœì†Œ 20GB RAM (3060 12GB + 2080 8GB)
- **ì €ì¥ê³µê°„**: ìµœì†Œ 50GB ì—¬ìœ  ê³µê°„
- **ë„¤íŠ¸ì›Œí¬**: ê³ ì† ì¸í„°ë„· (OpenAI API + GitHub Actions)

### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­
- **ìš´ì˜ì²´ì œ**: Windows 10/11 (64-bit)
- **Python**: 3.11 ì´ìƒ
- **CUDA**: 11.8/12.8 ì§€ì›
- **llama-cpp-python**: CUDA ì§€ì› ë²„ì „
- **MongoDB**: ë¡œì»¬ ì„¤ì¹˜
- **OpenAI API**: ìœ íš¨í•œ API í‚¤
- **GitHub**: Actions í™œì„±í™”

## ì•„í‚¤í…ì²˜

### í”„ë¡œì íŠ¸ êµ¬ì¡°
```
ğŸ“¦ ChatBot AI v1.6.x
â”œâ”€â”€ ğŸ“ .github/                  # GitHub Actions [NEW]
â”‚   â””â”€â”€ ğŸ“ workflows/
â”‚       â””â”€â”€ update-api-docs.yml [NEW]
â”œâ”€â”€ ğŸ“ fastapi/
â”‚   â”œâ”€â”€ ğŸ“ ai_model/             # GGUF ëª¨ë¸ ì €ì¥ì†Œ
â”‚   â”‚   â”œâ”€â”€ DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q8_0.gguf [NEW]
â”‚   â”‚   â”œâ”€â”€ llama-3-Korean-Bllossom-8B-Q4_K_M.gguf
â”‚   â”‚   â””â”€â”€ README.md [UPDATED]
â”‚   â”œâ”€â”€ ğŸ“ batch/                # í™˜ê²½ ì„¤ì • ë°°ì¹˜ íŒŒì¼
â”‚   â”‚   â”œâ”€â”€ venv_install.bat
â”‚   â”‚   â””â”€â”€ venv_setup.bat [UPDATED]
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ docs/             # API ëª…ì„¸ì„œ [NEW]
â”‚   â”‚   â”‚   â””â”€â”€ api_specification.md [NEW]
â”‚   â”‚   â”œâ”€â”€ ğŸ“ utils/            # ëª¨ë“ˆí™”ëœ ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ ai_models/    # AI ëª¨ë¸ ëª¨ë“ˆ
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama_character_model.py [RENAMED]
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llama_office_model.py [RENAMED]
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openai_character_model.py [UPDATED]
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ openai_office_model.py [UPDATED]
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ handlers/     # í•¸ë“¤ëŸ¬ ëª¨ë“ˆ
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ error_handler.py [COMPLETELY REDESIGNED]
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ routers/      # ì»¨íŠ¸ë¡¤ëŸ¬ íŒ¨í„´ [NEW]
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ office_controller.py [NEW]
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ character_controller.py [NEW]
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ schemas/      # ìŠ¤í‚¤ë§ˆ ëª¨ë“ˆ
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ chat_schema.py [UPDATED]
â”‚   â”‚   â”‚   â”œâ”€â”€ app_state.py [NEW]
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py [UPDATED]
â”‚   â”‚   â”œâ”€â”€ server.py [COMPLETELY REDESIGNED]
â”‚   â”‚   â”œâ”€â”€ bot.yaml
â”‚   â”‚   â””â”€â”€ .env
â”‚   â””â”€â”€ requirements.txt [UPDATED]
â”œâ”€â”€ ğŸ“ prompt/                   # í”„ë¡¬í”„íŠ¸ ë° ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ config-Llama.json [UPDATED]
â”‚   â””â”€â”€ config-OpenAI.json [UPDATED]
â”œâ”€â”€ CODE_OF_CONDUCT.md [UPDATED]
â””â”€â”€ README.md [UPDATED]
```

## API ëª…ì„¸

### ì»¨íŠ¸ë¡¤ëŸ¬ ê¸°ë°˜ API ì•„í‚¤í…ì²˜

#### Office Controller (`/office`)
ì—…ë¬´ ë° ì¼ë°˜ì ì¸ ì§ˆì˜ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬ì…ë‹ˆë‹¤.

##### POST /office/Llama
LlamaOffice GGUF ëª¨ë¸ ê¸°ë°˜ ê²€ìƒ‰ ì—°ë™ JSON ì‘ë‹µ

**ìš”ì²­ í˜•ì‹:**
```json
{
  "input_data": "string (1-500ì)",
  "google_access": "boolean (default: false)",
  "db_id": "string (UUID)",
  "user_id": "string"
}
```

**ì‘ë‹µ í˜•ì‹:**
- **Content-Type**: `application/json`
- **Response**: `"string"` (JSON ë¬¸ìì—´ ì§ì ‘ ë°˜í™˜)

##### POST /office/{gpt_set}
OpenAI GPT ëª¨ë¸ ê¸°ë°˜ ê²€ìƒ‰ ì—°ë™ JSON ì‘ë‹µ

**ê²½ë¡œ ë§¤ê°œë³€ìˆ˜:**
- `gpt_set`: OpenAI ëª¨ë¸ ë³„ì¹­
  - `gpt4o_mini` â†’ `gpt-4o-mini`
  - `gpt4.1` â†’ `gpt-4.1`
  - `gpt4.1_mini` â†’ `gpt-4.1-mini`

#### Character Controller (`/character`)
ìºë¦­í„° ê¸°ë°˜ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì»¨íŠ¸ë¡¤ëŸ¬ì…ë‹ˆë‹¤.

##### POST /character/Llama
LlamaCharacter GGUF ëª¨ë¸ ê¸°ë°˜ ìºë¦­í„° ëŒ€í™” JSON ì‘ë‹µ

**ìš”ì²­ í˜•ì‹:**
```json
{
  "input_data": "string (1-500ì)",
  "character_name": "string",
  "greeting": "string",
  "context": "string",
  "db_id": "string (UUID)",
  "user_id": "string"
}
```

##### POST /character/{gpt_set}
OpenAI GPT ëª¨ë¸ ê¸°ë°˜ ìºë¦­í„° ëŒ€í™” JSON ì‘ë‹µ

**ì˜ˆì‹œ ìš”ì²­:**
```json
{
  "input_data": "*I approach Rachel and talk to her.*",
  "character_name": "Rachel",
  "greeting": "*Rachel stands nervously at the lectern...*",
  "context": "Rachel is a devout Catholic girl of about 19 years old...",
  "db_id": "b440780c-cbaa-454f-a8d2-cf884786d89f",
  "user_id": "djjdjs74"
}
```

**HTTP ìƒíƒœ ì½”ë“œ:**
- `200`: ì„±ê³µ
- `400`: ì˜ëª»ëœ ìš”ì²­ (ì˜ëª»ëœ ëª¨ë¸ëª…)
- `422`: ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨
- `500`: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜

## ì£¼ìš” ì»´í¬ë„ŒíŠ¸

### 1. ì„œë²„ ì»´í¬ë„ŒíŠ¸ (server.py) - v1.6.x ì™„ì „ ì¬ì„¤ê³„

#### ì»¨íŠ¸ë¡¤ëŸ¬ íŒ¨í„´ ë„ì…
v1.5.xì˜ ë¼ìš°í„° í†µí•©ì—ì„œ **MVC ì»¨íŠ¸ë¡¤ëŸ¬ íŒ¨í„´**ìœ¼ë¡œ ì™„ì „ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.

```python
import utils.app_state as AppState
from utils import (
    LlamaOffice,
    LlamaCharacter,
    OfficeController,
    ChearacterController,
)

@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    FastAPI AI ëª¨ë¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” - v1.6.x
    ì»¨íŠ¸ë¡¤ëŸ¬ íŒ¨í„´ ê¸°ë°˜ ëª¨ë“ˆí™”ëœ ì‹œìŠ¤í…œ
    """
    def get_cuda_device_info(device_id: int) -> str:
        """
        ì£¼ì–´ì§„ CUDA ì¥ì¹˜ IDì— ëŒ€í•œ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        device_name = torch.cuda.get_device_name(device_id)
        device_properties = torch.cuda.get_device_properties(device_id)
        total_memory = device_properties.total_memory / (1024 ** 3)
        return f"Device {device_id}: {device_name} (Total Memory: {total_memory:.2f} GB)"
    
    try:
        # ê³µìœ  ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ
        AppState.LlamaOffice_model = LlamaOffice()          # cuda:1 (RTX 2080)
        AppState.LlamaCharacter_model = LlamaCharacter()    # cuda:0 (RTX 3060)
    except ChatError.InternalServerErrorException as e:
        print(f"{RED}ERROR{RESET}: ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        exit(1)
        
    # ë””ë²„ê¹…ìš© ì¶œë ¥
    LlamaOffice_device_info = get_cuda_device_info(1)      # LlamaOffice ëª¨ë¸ì€ cuda:1
    LlamaCharacter_device_info = get_cuda_device_info(0)   # LlamaCharacter ëª¨ë¸ì€ cuda:0
    print(f"{GREEN}INFO{RESET}: LlamaOffice ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({LlamaOffice_device_info})")
    print(f"{GREEN}INFO{RESET}: LlamaCharacter ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({LlamaCharacter_device_info})")

    yield

    # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
    AppState.LlamaOffice_model = None
    AppState.LlamaCharacter_model = None
    print(f"{GREEN}INFO{RESET}: ëª¨ë¸ í•´ì œ ì™„ë£Œ")

app = FastAPI(lifespan=lifespan)

# ì»¨íŠ¸ë¡¤ëŸ¬ ë“±ë¡
app.include_router(
    OfficeController.office_router,
    prefix="/office",
    tags=["Office API"],
    responses={500: {"description": "Internal Server Error"}}
)

app.include_router(
    ChearacterController.character_router,
    prefix="/character",
    tags=["Character API"],
    responses={500: {"description": "Internal Server Error"}}
)
```

#### ê°œì„ ëœ API ì •ë³´ ì‹œìŠ¤í…œ
ë²„ì „ ê´€ë¦¬ì™€ ë¡œê³ ê°€ ê°œì„ ëœ OpenAPI ëª…ì„¸ì„œì…ë‹ˆë‹¤.

```python
def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title="ChatBot AI API",
        version="v1.6.*",
        summary="AI ëª¨ë¸ ê´€ë¦¬ API",
        description=(
            "ì´ APIëŠ” AI ê¸°ë°˜ ì±—ë´‡ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n\n"
            "ì£¼ìš” ê¸°ëŠ¥:\n"
            "- LlamaOffice: ì—…ë¬´ìš© AI ì‘ë‹µ ìƒì„±\n"
            "- LlamaCharacter: ìºë¦­í„° ê¸°ë°˜ ëŒ€í™” ìƒì„±\n"
            "- OpenAI GPT: ê³ í’ˆì§ˆ AI ì‘ë‹µ ìƒì„±\n"
            "- DuckDuckGo ê²€ìƒ‰: ì‹¤ì‹œê°„ ì •ë³´ ê²€ìƒ‰ ì—°ë™"
        ),
        routes=app.routes,
    )
    openapi_schema["info"]["x-logo"] = {
        "url": "https://drive.google.com/thumbnail?id=12PqUS6bj4eAO_fLDaWQmoq94-771xfim"
    }
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi
```

### 2. ê³µìœ  ìƒíƒœ ê´€ë¦¬ ì»´í¬ë„ŒíŠ¸ (app_state.py) - v1.6.x ì‹ ê·œ

#### ì „ì—­ ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œ
ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì „ì—­ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ìƒíƒœ ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```python
"""
ì• í”Œë¦¬ì¼€ì´ì…˜ ì „ì—­ ìƒíƒœ ê´€ë¦¬ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì „ì—­ ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
ì£¼ë¡œ AI ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ì €ì¥í•˜ê³  ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.

ì „ì—­ ë³€ìˆ˜:
    LlamaOffice_model: Officeìš© Llama ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
    LlamaCharacter_model: Characterìš© Llama ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤

ì‚¬ìš© ì˜ˆì‹œ:
    from utils import app_state as AppState
    
    # ëª¨ë¸ í• ë‹¹
    AppState.LlamaOffice_model = LlamaOffice()
    
    # ëª¨ë¸ ì‚¬ìš©
    response = AppState.LlamaOffice_model.generate_response(input_text)
    
    # ëª¨ë¸ í•´ì œ
    AppState.LlamaOffice_model = None
"""

# AI ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë“¤ì„ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜
LlamaOffice_model = None
LlamaCharacter_model = None

def get_office_model():
    """Office ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return LlamaOffice_model

def get_character_model():
    """Character ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return LlamaCharacter_model

def set_office_model(model):
    """Office ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    global LlamaOffice_model
    LlamaOffice_model = model

def set_character_model(model):
    """Character ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    global LlamaCharacter_model
    LlamaCharacter_model = model

def clear_all_models():
    """ëª¨ë“  ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•´ì œí•©ë‹ˆë‹¤."""
    global LlamaOffice_model, LlamaCharacter_model
    LlamaOffice_model = None
    LlamaCharacter_model = None
```

### 3. ì»¨íŠ¸ë¡¤ëŸ¬ ì»´í¬ë„ŒíŠ¸ - v1.6.x ì‹ ê·œ

#### OfficeController í´ë˜ìŠ¤ (office_controller.py) - ì‹ ê·œ ì¶”ê°€

Office ë¼ìš°í„° ë¡œì§ì„ ì™„ì „íˆ ë¶„ë¦¬í•œ ì»¨íŠ¸ë¡¤ëŸ¬ì…ë‹ˆë‹¤.

```python
"""
Office ë¼ìš°í„° ì»¨íŠ¸ë¡¤ëŸ¬

ì—…ë¬´ ë° ì¼ë°˜ì ì¸ ì§ˆì˜ì‘ë‹µì„ ì²˜ë¦¬í•˜ëŠ” ë¼ìš°í„° ì»¨íŠ¸ë¡¤ëŸ¬ì…ë‹ˆë‹¤.
DuckDuckGo ê²€ìƒ‰ ì—°ë™ê³¼ MongoDB ì±„íŒ… ê¸°ë¡ ê´€ë¦¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

ì§€ì› ëª¨ë¸:
- LlamaOffice: Bllossom-8B GGUF ëª¨ë¸
- OpenAI GPT: GPT-4o-mini, GPT-4.1, GPT-4.1-mini

ì£¼ìš” ê¸°ëŠ¥:
- ê²€ìƒ‰ ê¸°ë°˜ ì‘ë‹µ ìƒì„±
- ì±„íŒ… ê¸°ë¡ ê´€ë¦¬
- JSON ì‘ë‹µ í˜•ì‹
"""

from fastapi import APIRouter, Path, HTTPException
from pydantic import ValidationError
import utils.app_state as AppState
from utils import ChatModel, ChatError, ChatSearch, MongoDBHandler, OpenAiOffice

# OpenAI ëª¨ë¸ ë§¤í•‘
OPENAI_MODEL_MAP = {
    "gpt4o_mini": "gpt-4o-mini",
    "gpt4.1": "gpt-4.1",
    "gpt4.1_mini": "gpt-4.1-mini",
}

office_router = APIRouter()

# MongoDB í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
try:
    mongo_handler = MongoDBHandler()
except Exception as e:
    mongo_handler = None
    print(f"MongoDB ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")

@office_router.post("/Llama", summary="Llama ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±")
async def office_llama(request: ChatModel.office_Request):
    """
    LlamaOffice GGUF ëª¨ë¸ ê¸°ë°˜ ê²€ìƒ‰ ì—°ë™ ì‘ë‹µ
    """
    chat_list = []
    search_context = ""
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler and request.db_id:
        try:
            chat_list = await mongo_handler.get_office_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="office",
            )
        except Exception as e:
            print(f"WARNING: ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

    # DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    if request.google_access:
        try:
            duck_results = await ChatSearch.fetch_duck_search_results(query=request.input_data)
            
            if duck_results:
                formatted_results = []
                for idx, item in enumerate(duck_results[:10], 1):
                    formatted_result = (
                        f"[ê²€ìƒ‰ê²°ê³¼ {idx}]\n"
                        f"ì œëª©: {item.get('title', 'ì œëª© ì—†ìŒ')}\n"
                        f"ë‚´ìš©: {item.get('snippet', 'ë‚´ìš© ì—†ìŒ')}\n"
                        f"ì¶œì²˜: {item.get('link', 'ë§í¬ ì—†ìŒ')}\n"
                    )
                    formatted_results.append(formatted_result)
                
                search_context = (
                    "ë‹¤ìŒì€ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\n\n" +
                    "\n".join(formatted_results)
                )
        except Exception:
            print("WARNING: DuckDuckGo ê²€ìƒ‰ ì‹¤íŒ¨")
            search_context = ""

    try:        
        full_response = AppState.LlamaOffice_model.generate_response(
            input_text=request.input_data,
            search_text=search_context,
            chat_list=chat_list,
        )
        return full_response

    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@office_router.post("/{gpt_set}", summary="GPT ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±")
async def office_gpt(
        request: ChatModel.office_Request,
        gpt_set: str = Path(
            ...,
            title="GPT ëª¨ë¸ëª…",
            description="ì‚¬ìš©í•  OpenAI GPT ëª¨ë¸ì˜ ë³„ì¹­",
            examples=list(OPENAI_MODEL_MAP.keys()),
        )
    ):
    """
    OpenAI GPT ëª¨ë¸ ê¸°ë°˜ ê²€ìƒ‰ ì—°ë™ ì‘ë‹µ
    """
    if gpt_set not in OPENAI_MODEL_MAP:
        raise HTTPException(status_code=400, detail="Invalid model name.")

    model_id = OPENAI_MODEL_MAP[gpt_set]
    chat_list = []
    search_context = ""

    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler and request.db_id:
        try:
            chat_list = await mongo_handler.get_office_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="office",
            )
        except Exception as e:
            print(f"WARNING: ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

    # DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (office_llamaì™€ ë™ì¼ ë¡œì§)
    if request.google_access:
        # ... (ê²€ìƒ‰ ë¡œì§ ë™ì¼)

    OpenAiOffice_model = OpenAiOffice(model_id=model_id)
    try:
        full_response = OpenAiOffice_model.generate_response(
            input_text=request.input_data,
            search_text=search_context,
            chat_list=chat_list,
        )
        return full_response

    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
```

#### CharacterController í´ë˜ìŠ¤ (character_controller.py) - ì‹ ê·œ ì¶”ê°€

Character ë¼ìš°í„° ë¡œì§ì„ ì™„ì „íˆ ë¶„ë¦¬í•œ ì»¨íŠ¸ë¡¤ëŸ¬ì…ë‹ˆë‹¤.

```python
"""
Character ë¼ìš°í„° ì»¨íŠ¸ë¡¤ëŸ¬

ìºë¦­í„° ê¸°ë°˜ ëŒ€í™”ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë¼ìš°í„° ì»¨íŠ¸ë¡¤ëŸ¬ì…ë‹ˆë‹¤.
MongoDB ì±„íŒ… ê¸°ë¡ ê´€ë¦¬ì™€ ìºë¦­í„° ì„¤ì • ê´€ë¦¬ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.

ì§€ì› ëª¨ë¸:
- LlamaCharacter: DarkIdol-Llama-3.1-8B GGUF ëª¨ë¸
- OpenAI GPT: GPT-4o-mini, GPT-4.1, GPT-4.1-mini

ì£¼ìš” ê¸°ëŠ¥:
- ìºë¦­í„° ê¸°ë°˜ ëŒ€í™” ìƒì„±
- ì±„íŒ… ê¸°ë¡ ê´€ë¦¬
- JSON ì‘ë‹µ í˜•ì‹
"""

from fastapi import APIRouter, Path, HTTPException
from pydantic import ValidationError
import utils.app_state as AppState
from utils import ChatModel, ChatError, MongoDBHandler, OpenAiCharacter

# OpenAI ëª¨ë¸ ë§¤í•‘
OPENAI_MODEL_MAP = {
    "gpt4o_mini": "gpt-4o-mini",
    "gpt4.1": "gpt-4.1",
    "gpt4.1_mini": "gpt-4.1-mini",
}

character_router = APIRouter()

# MongoDB í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
try:
    mongo_handler = MongoDBHandler()
except Exception as e:
    mongo_handler = None
    print(f"MongoDB ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")

@character_router.post("/Llama", summary="Llama ëª¨ë¸ì´ ìºë¦­í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±")
async def character_llama(request: ChatModel.character_Request):
    """
    LlamaCharacter GGUF ëª¨ë¸ ê¸°ë°˜ ìºë¦­í„° ëŒ€í™”
    """
    chat_list = []
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler and request.db_id:
        try:
            chat_list = await mongo_handler.get_character_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="character",
            )
        except Exception as e:
            print(f"WARNING: ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")
            
    try:
        character_settings = {
            "character_name": request.character_name,
            "greeting": request.greeting,
            "context": request.context,
            "chat_list": chat_list,
        }
        full_response = AppState.LlamaCharacter_model.generate_response(
            input_text=request.input_data,
            character_settings=character_settings,
        )
        return full_response

    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@character_router.post("/{gpt_set}", summary="GPT ëª¨ë¸ì´ ìºë¦­í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±")
async def character_gpt(
        request: ChatModel.character_Request,
        gpt_set: str = Path(
            ...,
            title="GPT ëª¨ë¸ëª…",
            description="ì‚¬ìš©í•  OpenAI GPT ëª¨ë¸ì˜ ë³„ì¹­",
            examples=list(OPENAI_MODEL_MAP.keys()),
        )
    ):
    """
    OpenAI GPT ëª¨ë¸ ê¸°ë°˜ ìºë¦­í„° ëŒ€í™”
    """
    if gpt_set not in OPENAI_MODEL_MAP:
        raise HTTPException(status_code=400, detail="Invalid model name.")

    model_id = OPENAI_MODEL_MAP[gpt_set]
    chat_list = []
    
    # MongoDBì—ì„œ ì±„íŒ… ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
    if mongo_handler and request.db_id:
        try:
            chat_list = await mongo_handler.get_character_log(
                user_id=request.user_id,
                document_id=request.db_id,
                router="character",
            )
        except Exception as e:
            print(f"WARNING: ì±„íŒ… ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

    OpenAiCharacter_model = OpenAiCharacter(model_id=model_id)
    try:
        character_settings = {
            "character_name": request.character_name,
            "greeting": request.greeting,
            "context": request.context,
            "chat_list": chat_list,
        }
        full_response = OpenAiCharacter_model.generate_response(
            input_text=request.input_data,
            character_settings=character_settings,
        )
        return full_response

    except Exception as e:
        print(f"ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì˜ˆì™¸: {e}")
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
```

### 4. ì˜ˆì™¸ ì²˜ë¦¬ ì»´í¬ë„ŒíŠ¸ (error_handler.py) - v1.6.x ì™„ì „ ì¬ì„¤ê³„

#### ExceptionManager í´ë˜ìŠ¤ ë„ì…
í†µí•©ëœ ì˜ˆì™¸ ì²˜ë¦¬ ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```python
"""
FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë°œìƒí•˜ëŠ” ì˜ˆì™¸ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.
v1.6.xì—ì„œ ExceptionManager í´ë˜ìŠ¤ íŒ¨í„´ìœ¼ë¡œ ì™„ì „ ì¬ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
"""

import uuid
import os
import logging
import traceback
from datetime import datetime
from typing import Callable, Dict, Optional, Type, Any

from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from sqlalchemy.exc import SQLAlchemyError
from starlette.middleware.base import BaseHTTPMiddleware

# ==========================
# 1. ë¡œê·¸ ë””ë ‰í† ë¦¬ ë° ì„¤ì •
# ==========================
BASE_DIR = os.path.dirname(
    os.path.dirname(
        os.path.dirname(
            os.path.abspath(__file__)
        )
    )
)
LOG_DIR = os.path.join(BASE_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

class DailyRotatingFileHandler(logging.handlers.BaseRotatingHandler):
    """
    ë‚ ì§œë³„ ë¡œê·¸ íŒŒì¼ì„ ìƒì„±í•˜ëŠ” ì»¤ìŠ¤í…€ í•¸ë“¤ëŸ¬ì…ë‹ˆë‹¤.
    """
    def __init__(self, dir_path: str, date_format: str = "%Y%m%d", encoding=None):
        self.dir_path = dir_path
        self.date_format = date_format
        self.current_date = datetime.now().strftime(self.date_format)
        log_file = os.path.join(dir_path, f"error_{self.current_date}.log")
        super().__init__(log_file, 'a', encoding)

    def shouldRollover(self, record):
        return datetime.now().strftime(self.date_format) != self.current_date

    def doRollover(self):
        self.stream.close()
        self.current_date = datetime.now().strftime(self.date_format)
        log_file = os.path.join(self.dir_path, f"error_{self.current_date}.log")
        self.baseFilename = log_file
        self.stream = self._open()

# ==========================
# 2. Logger êµ¬ì„±
# ==========================
logger = logging.getLogger("fastapi_error_handlers")
logger.setLevel(logging.DEBUG)

formatter = logging.Formatter(
    '[%(asctime)s] %(levelname)s in %(module)s:\n%(message)s\n',
    datefmt='%Y-%m-%d %H:%M:%S'
)

file_handler = DailyRotatingFileHandler(LOG_DIR, encoding='utf-8')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

stream_handler = logging.StreamHandler()
stream_handler.setFormatter(formatter)
logger.addHandler(stream_handler)

# ==========================
# 3. ì˜ˆì™¸ í´ë˜ìŠ¤ ì •ì˜
# ==========================
class BaseCustomException(HTTPException):
    def __init__(self, status_code: int, detail: str):
        super().__init__(status_code=status_code, detail=detail)

class NotFoundException(BaseCustomException):
    def __init__(self, detail="Resource not found"):
        super().__init__(404, detail)

class BadRequestException(BaseCustomException):
    def __init__(self, detail="Bad request"):
        super().__init__(400, detail)

class UnauthorizedException(BaseCustomException):
    def __init__(self, detail="Unauthorized"):
        super().__init__(401, detail)

class ForbiddenException(BaseCustomException):
    def __init__(self, detail="Forbidden"):
        super().__init__(403, detail)

class ValueErrorException(BaseCustomException):
    def __init__(self, detail="Invalid value"):
        super().__init__(422, detail)

class InternalServerErrorException(BaseCustomException):
    def __init__(self, detail="Internal Server Error"):
        trace_id = uuid.uuid4()
        super().__init__(500, detail)

class DatabaseErrorException(BaseCustomException):
    def __init__(self, detail="Database Error"):
        super().__init__(503, detail)

class IPRestrictedException(BaseCustomException):
    def __init__(self, detail="Unauthorized IP address"):
        super().__init__(403, detail)

class MethodNotAllowedException(BaseCustomException):
    def __init__(self, detail="Method Not Allowed"):
        super().__init__(405, detail)

class RouteNotFoundException(BaseCustomException):
    def __init__(self, detail="Route not found"):
        super().__init__(404, detail)

# ==========================
# 4. í•¸ë“¤ëŸ¬ í•¨ìˆ˜
# ==========================
def log_error(
    *,
    exc: Exception,
    request: Request,
    status_code: int,
    detail: str,
    extra: dict = None
):
    """
    ì—ëŸ¬ ì •ë³´ë¥¼ ë¡œê·¸ë¡œ ê¸°ë¡í•˜ëŠ” í•¨ìˆ˜.
    """
    body = ""
    try:
        body = request._body.decode('utf-8') if hasattr(request, "_body") and request._body else ""
    except Exception:
        pass

    client_ip = request.client.host if request.client else "Unknown"
    query_params = dict(request.query_params)

    # í¬ë§·í„°ì— ë§¡ê¸°ê³ , ë©”ì‹œì§€ëŠ” ë³¸ë¬¸ë§Œ ì‘ì„±
    log_msg = (
        f"{'='*80}\n"
        f"Error Type: {type(exc).__name__}\n"
        f"Status: {status_code}\n"
        f"Detail: {detail}\n"
        f"URL: {request.url}\n"
        f"Method: {request.method}\n"
        f"Client IP: {client_ip}\n"
        f"Body: {body}\n"
        f"Query: {query_params}\n"
    )

    # tracebackì´ extraì— ìˆìœ¼ë©´ ë³„ë„ë¡œ ì¶”ê°€
    if extra and "traceback" in extra:
        log_msg += f"Traceback:\n{extra['traceback']}\n"
    if extra:
        log_msg += f"Extra: {extra}\n"
    log_msg += f"{'='*80}"
    
    logger.error(log_msg)

class ExceptionHandlerFactory:
    """
    ì˜ˆì™¸ í•¸ë“¤ëŸ¬ íŒ©í† ë¦¬ í´ë˜ìŠ¤
    """
    handlers: Dict[Type[HTTPException], Callable[[Request, HTTPException], JSONResponse]] = {
        NotFoundException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": "Not found"}),
        BadRequestException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": "Bad request"}),
        UnauthorizedException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": "Unauthorized"}),
        ForbiddenException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": "Forbidden"}),
        ValueErrorException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": "Invalid input"}),
        InternalServerErrorException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": "Server error"}),
        DatabaseErrorException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": "Database error"}),
        IPRestrictedException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": exc.detail}),
        MethodNotAllowedException: lambda req, exc: JSONResponse(status_code=exc.status_code, content={"detail": "Not allowed"})
    }

    @staticmethod
    async def generic_handler(request: Request, exc: HTTPException) -> JSONResponse:
        handler = ExceptionHandlerFactory.handlers.get(type(exc))
        log_error(
            exc=exc,
            request=request,
            status_code=exc.status_code,
            detail=exc.detail
        )
        return handler(request, exc) if handler else JSONResponse(
            status_code=500,
            content={"detail": "Unexpected error", "type": type(exc).__name__}
        )

    @staticmethod
    async def validation_handler(request: Request, exc: RequestValidationError) -> JSONResponse:
        error_details = [
            {"location": err["loc"], "message": err["msg"], "type": err["type"]}
            for err in exc.errors()
        ]
        log_error(
            exc=exc,
            request=request,
            status_code=422,
            detail="ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨",
            extra={"validation_errors": error_details}
        )
        return JSONResponse(status_code=422, content={"detail": error_details, "message": "ì…ë ¥ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨"})

    @staticmethod
    async def database_handler(request: Request, exc: SQLAlchemyError) -> JSONResponse:
        log_error(
            exc=exc,
            request=request,
            status_code=503,
            detail="ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜",
            extra={"traceback": traceback.format_exc()}
        )
        return JSONResponse(status_code=503, content={"detail": "ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜", "message": "ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."})

# ==========================
# 5. ExceptionManager í´ë˜ìŠ¤
# ==========================
class ExceptionManager:
    """
    ì˜ˆì™¸ ì²˜ë¦¬ ê´€ë¦¬ì í´ë˜ìŠ¤ - v1.6.x ì‹ ê·œ
    """
    @staticmethod
    def register(app: FastAPI):
        """
        FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ì— ëª¨ë“  ì˜ˆì™¸ í•¸ë“¤ëŸ¬ë¥¼ ë“±ë¡í•©ë‹ˆë‹¤.
        
        Args:
            app: FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì¸ìŠ¤í„´ìŠ¤
        """
        # ì»¤ìŠ¤í…€ ì˜ˆì™¸ í•¸ë“¤ëŸ¬ ë“±ë¡
        for exc_type in ExceptionHandlerFactory.handlers:
            app.add_exception_handler(exc_type, ExceptionHandlerFactory.generic_handler)
        
        # ê²€ì¦ ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ ë“±ë¡
        app.add_exception_handler(RequestValidationError, ExceptionHandlerFactory.validation_handler)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì˜¤ë¥˜ í•¸ë“¤ëŸ¬ ë“±ë¡
        app.add_exception_handler(SQLAlchemyError, ExceptionHandlerFactory.database_handler)
        
        # ì—ëŸ¬ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
        app.add_middleware(ErrorLoggingMiddleware)

# ==========================
# 6. ë¯¸ë“¤ì›¨ì–´
# ==========================
class ErrorLoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next: Callable) -> Any:
        try:
            return await call_next(request)
        except Exception as exc:
            log_error(
                exc=exc,
                request=request,
                status_code=500,
                detail="Unhandled exception",
                extra={"traceback": traceback.format_exc()}
            )
            raise exc

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
add_exception_handlers = ExceptionManager.register
generic_exception_handler = ExceptionHandlerFactory.generic_handler
```

### 5. AI ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ - v1.6.x ëª¨ë¸ëª… ë³€ê²½

#### LlamaOfficeModel í´ë˜ìŠ¤ (llama_office_model.py) - ì´ë¦„ ë³€ê²½

`bllossom_model.py`ì—ì„œ `llama_office_model.py`ë¡œ ì´ë¦„ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.

```python
class LlamaOfficeModel:
    """
    GGUF í¬ë§·ìœ¼ë¡œ ê²½ëŸ‰í™”ëœ Llama-3-Korean-Bllossom-8B ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , 
    ì£¼ì–´ì§„ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    
    v1.6.xì—ì„œ BllossomChatModelì—ì„œ LlamaOfficeModelë¡œ ì´ë¦„ ë³€ê²½
    """
    def __init__(self) -> None:
        """
        GGUF ëª¨ë¸ ì´ˆê¸°í™” - RTX 2080 ìµœì í™”
        """
        self.model_id = "llama-3-Korean-Bllossom-8B-Q4_K_M"
        self.model_path = "fastapi/ai_model/llama-3-Korean-Bllossom-8B-Q4_K_M.gguf"
        self.file_path = './prompt/config-Llama.json'
        self.gpu_layers: int = 70
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model: Llama = self._load_model()
        self.response_queue: Queue = Queue()

    def generate_response(self, input_text: str, search_text: str, chat_list: List[Dict]) -> str:
        """
        JSON ì‘ë‹µ ìƒì„± ë©”ì„œë“œ - v1.6.x ìµœì í™”
        """
        try:
            current_time = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„")
            # ì‘ë‹µ ìƒì„± ë¡œì§
            chunks = []
            for chunk in self.create_streaming_completion(
                prompt=prompt,
                max_tokens=2048,
                temperature=0.5,
                top_p=0.80,
                stop=["<|eot_id|>"]
            ):
                chunks.append(chunk)
            
            return "".join(chunks)

        except Exception as e:
            return f"ì˜¤ë¥˜: {str(e)}"
```

#### LlamaCharacterModel í´ë˜ìŠ¤ (llama_character_model.py) - ì´ë¦„ ë³€ê²½

`lumimaid_model.py`ì—ì„œ `llama_character_model.py`ë¡œ ì´ë¦„ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.

```python
class LlamaCharacterModel:
    """
    GGUF í¬ë§·ìœ¼ë¡œ ê²½ëŸ‰í™”ëœ DarkIdol-Llama-3.1-8B ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , 
    ìºë¦­í„° ê¸°ë°˜ ëŒ€í™” ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    
    v1.6.xì—ì„œ LumimaidChatModelì—ì„œ LlamaCharacterModelë¡œ ì´ë¦„ ë³€ê²½
    DarkIdol-Llama-3.1-8B ëª¨ë¸ë¡œ ì—…ê·¸ë ˆì´ë“œ
    """
    def __init__(self) -> None:
        """
        GGUF ëª¨ë¸ ì´ˆê¸°í™” - RTX 3060 ìµœì í™”
        """
        self.model_id = "DarkIdol-Llama-3.1-8B"
        self.model_path = "fastapi/ai_model/DarkIdol-Llama-3.1-8B-Instruct-1.2-Uncensored.Q8_0.gguf"
        self.file_path = './prompt/config-Llama.json'
        self.gpu_layers: int = 70
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.model: Llama = self._load_model()
        self.response_queue: Queue = Queue()

    def generate_response(self, input_text: str, character_settings: dict = None) -> str:
        """
        ìºë¦­í„° ê¸°ë°˜ JSON ì‘ë‹µ ìƒì„± ë©”ì„œë“œ - v1.6.x ìµœì í™”
        """
        try:
            if character_settings:
                character_info = CharacterPrompt(
                    name=character_settings.get("character_name", "Assistant"),
                    greeting=character_settings.get("greeting", ""),
                    context=character_settings.get("context", ""),
                    user_input=input_text,
                    chat_list=character_settings.get("chat_list", [])
                )
                # Llama3 messages í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                messages = build_llama3_messages(character_info, input_text, chat_list)
            else:
                messages = [{"role": "user", "content": input_text}]
            
            chunks = []
            for chunk in self.create_streaming_completion(
                messages=messages,
                max_tokens=2048,
                temperature=0.7,
                top_p=0.95,
                stop=["<|eot_id|>"]
            ):
                chunks.append(chunk)
            
            return "".join(chunks)

        except Exception as e:
            return f"ì˜¤ë¥˜: {str(e)}"
```

### 6. ìë™í™” ì‹œìŠ¤í…œ - v1.6.x ì‹ ê·œ

#### GitHub Actions CI/CD (update-api-docs.yml)

API ëª…ì„¸ì„œ ìë™ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ GitHub Actions ì›Œí¬í”Œë¡œìš°ì…ë‹ˆë‹¤.

```yaml
name: Update API Documentation

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'fastapi/src/**/*.py'
      - 'fastapi/requirements.txt'
  pull_request:
    branches: [ main ]
    paths:
      - 'fastapi/src/**/*.py'

jobs:
  update-docs:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        fetch-depth: 0
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install fastapi uvicorn pydantic
        
    - name: Extract API endpoints
      run: |
        python -c "
        import sys
        import os
        sys.path.append('fastapi/src')
        
        # API ì—”ë“œí¬ì¸íŠ¸ ì¶”ì¶œ ìŠ¤í¬ë¦½íŠ¸
        from fastapi import FastAPI
        from utils.routers import office_controller, character_controller
        
        app = FastAPI()
        app.include_router(office_controller.office_router, prefix='/office')
        app.include_router(character_controller.character_router, prefix='/character')
        
        # OpenAPI ìŠ¤í‚¤ë§ˆ ìƒì„±
        openapi_schema = app.openapi()
        
        # Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        markdown_content = '''# ChatBot AI - API ëª…ì„¸ì„œ
        
## ê°œìš”
ì´ ë¬¸ì„œëŠ” ChatBot AI APIì˜ ìë™ ìƒì„±ëœ ëª…ì„¸ì„œì…ë‹ˆë‹¤.

## ì—”ë“œí¬ì¸íŠ¸

'''
        
        for path, methods in openapi_schema['paths'].items():
            markdown_content += f'### {path}\n\n'
            for method, details in methods.items():
                markdown_content += f'#### {method.upper()}\n'
                markdown_content += f'{details.get(\"summary\", \"No summary\")}\n\n'
                
        # íŒŒì¼ ì €ì¥
        with open('fastapi/src/docs/api_specification.md', 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        "
        
    - name: Commit and push if changed
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add fastapi/src/docs/api_specification.md
        git diff --staged --quiet || git commit -m "docs: Update API specification [automated]"
        git push
```

#### API ëª…ì„¸ì„œ ìë™ ìƒì„± (api_specification.md)

FastAPI OpenAPI ìŠ¤í‚¤ë§ˆì—ì„œ ìë™ ìƒì„±ë˜ëŠ” API ë¬¸ì„œì…ë‹ˆë‹¤.

```markdown
# ChatBot AI - API ëª…ì„¸ì„œ

## ê°œìš”
ì´ ë¬¸ì„œëŠ” ChatBot AI APIì˜ ìë™ ìƒì„±ëœ ëª…ì„¸ì„œì…ë‹ˆë‹¤.
GitHub Actionsë¥¼ í†µí•´ ì½”ë“œ ë³€ê²½ ì‹œ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.

## ì—…ë°ì´íŠ¸ ì •ë³´
- **ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-06-28 20:34:20
- **API ë²„ì „**: v1.6.*
- **FastAPI ë²„ì „**: 0.112.0

## ì—”ë“œí¬ì¸íŠ¸

### Office API (`/office`)

#### POST /office/Llama
**ìš”ì•½**: Llama ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±

**ì„¤ëª…**: LlamaOffice GGUF ëª¨ë¸ ê¸°ë°˜ ê²€ìƒ‰ ì—°ë™ ì‘ë‹µ

**ìš”ì²­ ìŠ¤í‚¤ë§ˆ**:
```json
{
  "input_data": "string",
  "google_access": "boolean",
  "db_id": "string",
  "user_id": "string"
}
```

**ì‘ë‹µ**: JSON ë¬¸ìì—´

#### POST /office/{gpt_set}
**ìš”ì•½**: GPT ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±

**ì„¤ëª…**: OpenAI GPT ëª¨ë¸ ê¸°ë°˜ ê²€ìƒ‰ ì—°ë™ ì‘ë‹µ

**ê²½ë¡œ ë§¤ê°œë³€ìˆ˜**:
- `gpt_set`: ì‚¬ìš©í•  GPT ëª¨ë¸ (gpt4o_mini, gpt4.1, gpt4.1_mini)

### Character API (`/character`)

#### POST /character/Llama
**ìš”ì•½**: Llama ëª¨ë¸ì´ ìºë¦­í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±

**ì„¤ëª…**: LlamaCharacter GGUF ëª¨ë¸ ê¸°ë°˜ ìºë¦­í„° ëŒ€í™”

**ìš”ì²­ ìŠ¤í‚¤ë§ˆ**:
```json
{
  "input_data": "string",
  "character_name": "string",
  "greeting": "string",
  "context": "string",
  "db_id": "string",
  "user_id": "string"
}
```

#### POST /character/{gpt_set}
**ìš”ì•½**: GPT ëª¨ë¸ì´ ìºë¦­í„° ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„±

**ì„¤ëª…**: OpenAI GPT ëª¨ë¸ ê¸°ë°˜ ìºë¦­í„° ëŒ€í™”

## ì˜¤ë¥˜ ì½”ë“œ

| ì½”ë“œ | ì„¤ëª… | í•´ê²° ë°©ë²• |
|------|------|-----------|
| 400 | ì˜ëª»ëœ ìš”ì²­ | ìš”ì²­ í˜•ì‹ í™•ì¸ |
| 403 | ì ‘ê·¼ ê±°ë¶€ | IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ í™•ì¸ |
| 422 | ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨ | ì…ë ¥ ë°ì´í„° í˜•ì‹ í™•ì¸ |
| 500 | ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ | ì„œë²„ ë¡œê·¸ í™•ì¸ |

## ì‚¬ìš© ì˜ˆì‹œ

### Office API í˜¸ì¶œ
```bash
curl -X POST "https://your-domain/office/Llama" \
  -H "Content-Type: application/json" \
  -d '{
    "input_data": "ChatBot AIì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    "google_access": true,
    "db_id": "12345678-1234-1234-1234-123456789012",
    "user_id": "user123"
  }'
```

### Character API í˜¸ì¶œ
```bash
curl -X POST "https://your-domain/character/Llama" \
  -H "Content-Type: application/json" \
  -d '{
    "input_data": "ì•ˆë…•í•˜ì„¸ìš”!",
    "character_name": "ì¹œì ˆí•œ ë„ìš°ë¯¸",
    "greeting": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?",
    "context": "ì¹œì ˆí•˜ê³  ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸",
    "db_id": "12345678-1234-1234-1234-123456789012",
    "user_id": "user123"
  }'
```

---
*ì´ ë¬¸ì„œëŠ” GitHub Actionsë¥¼ í†µí•´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*
```

## ì„¤ì¹˜ ë° ì„¤ì •

### í™˜ê²½ ì„¤ì • ì‹œìŠ¤í…œ - v1.6.x í†µí•©

#### ê°œì„ ëœ ê°€ìƒí™˜ê²½ ì„¤ì •
Windows PowerShell í˜¸í™˜ì„±ì´ ê°œì„ ëœ ë°°ì¹˜ íŒŒì¼ì…ë‹ˆë‹¤.

```batch
@echo off
chcp 65001
SETLOCAL

:: Python ì„¤ì¹˜ ê²½ë¡œ ì„¤ì • (ê³µë°± ì—†ì´)
SET PYTHON_PATH=C:\Users\%USERNAME%\AppData\Local\Programs\Python\Python311\python.exe

:: ê°€ìƒ í™˜ê²½ ë””ë ‰í† ë¦¬ ì´ë¦„ ì„¤ì • (ê³µë°± ì—†ì´)
SET ENV_DIR=.venv

"%PYTHON_PATH%" -m venv %ENV_DIR%

IF NOT EXIST "%ENV_DIR%\Scripts\activate.ps1" (
    echo ê°€ìƒ í™˜ê²½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.
    EXIT /B 1
)

echo ê°€ìƒ í™˜ê²½ í™œì„±í™” ì¤‘...
powershell -NoExit -ExecutionPolicy Bypass -Command "& { .\%ENV_DIR%\Scripts\Activate.ps1 }"

ENDLOCAL
```

#### í†µì¼ëœ íŒ¨í‚¤ì§€ ë²„ì „ ê´€ë¦¬
ì½”ë“œ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ íŒ¨í‚¤ì§€ ë²„ì „ í†µì¼í™”ì…ë‹ˆë‹¤.

```bash
# requirements.txt - v1.6.x ì—…ë°ì´íŠ¸
torch==2.3.1+cu118
torchvision==0.18.1+cu118
torchaudio==2.3.1+cu118
-f https://download.pytorch.org/whl/torch_stable.html

# OpenAI API
openai

# FastAPI ê´€ë ¨
fastapi==0.112.0
uvicorn==0.30.5

# ìœ í‹¸ë¦¬í‹° íŒ¨í‚¤ì§€ (ë²„ì „ í†µì¼)
python-dotenv==1.0.1
requests==2.32.3
httpx==0.27.0
itsdangerous==2.2.0

# AI ê´€ë ¨
bitsandbytes
accelerate>=0.26.0

# ê¸°íƒ€ ì˜ì¡´ì„± íŒ¨í‚¤ì§€ (== ë²„ì „ ê³ ì •)
annotated-types==0.7.0
anyio==4.4.0
click>=8.1.7
colorama==0.4.6
dnspython==2.6.1
h11==0.14.0
idna==3.7
pydantic==2.8.2
pydantic_core==2.20.1
setuptools==65.5.0
sniffio==1.3.1
starlette==0.37.2
typing_extensions==4.12.2

# GGUF ë° ê²€ìƒ‰
ua-parser
motor
llama-cpp-python[cuda]
gguf
duckduckgo-search
langchain-community

# ìì—°ì–´ ì²˜ë¦¬
spacy
deep-translator>=1.11.4
Pillow
```

### GitHub í†µí•© ì„¤ì •
CI/CD íŒŒì´í”„ë¼ì¸ê³¼ ìë™ ë¬¸ì„œí™”ë¥¼ ìœ„í•œ ì„¤ì •ì…ë‹ˆë‹¤.

```bash
# GitHub Actions í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
MONGODB_URI: ${{ secrets.MONGODB_URI }}

# ë¡œì»¬ ê°œë°œ í™˜ê²½ ì„¤ì •
git config core.autocrlf true
git config push.default current
```

## ì„±ëŠ¥ íŠ¹ì„±

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **LlamaOffice (GGUF)**: ~8GB VRAM (RTX 2080)
- **LlamaCharacter (GGUF)**: ~6GB VRAM (RTX 3060)
- **OpenAI API**: ~0MB VRAM (ì™¸ë¶€ API)
- **AppState ê´€ë¦¬**: ~64MB RAM
- **ë¡œê·¸ ì‹œìŠ¤í…œ**: ~32MB RAM (ì¼ë³„ ë¡œí…Œì´ì…˜)
- **ì‹œìŠ¤í…œ RAM**: ~8-10GB

### ì²˜ë¦¬ëŸ‰
- **ë™ì‹œ ìš”ì²­**: 4ê°œ (ì»¨íŠ¸ë¡¤ëŸ¬ ë¶„ì‚° ì²˜ë¦¬)
- **ì‹œê°„ë‹¹ ìš”ì²­**: ~1000-1500ê°œ
- **ì»¨íŠ¸ë¡¤ëŸ¬ ì˜¤ë²„í—¤ë“œ**: ìµœì†Œ (~2ms)
- **GitHub Actions**: í‘¸ì‹œë‹¹ ~30ì´ˆ (ë¬¸ì„œ ì—…ë°ì´íŠ¸)

### API ì‘ë‹µ ì‹œê°„
- **Office/Llama**: 8-25ì´ˆ (Bllossom Q4_K_M)
- **Office/GPT**: 2-5ì´ˆ (OpenAI API)
- **Character/Llama**: 10-30ì´ˆ (DarkIdol Q8_0)
- **Character/GPT**: 3-7ì´ˆ (OpenAI API)

## ìš´ì˜ ê°€ì´ë“œ

### í™˜ê²½ ì„¤ì •
1. **GitHub ë¦¬í¬ì§€í† ë¦¬** ì„¤ì • (Actions í™œì„±í™”)
2. **Windows 11** + **Python 3.11** í™˜ê²½ êµ¬ì„±
3. **OpenAI API í‚¤** ë°œê¸‰ ë° ì„¤ì •
4. **CUDA 11.8/12.8** ë“œë¼ì´ë²„ ì„¤ì¹˜
5. **ë¡œì»¬ MongoDB** ì„¤ì¹˜ ë° êµ¬ì„±
6. **GGUF ëª¨ë¸** ë‹¤ìš´ë¡œë“œ ë° ë°°ì¹˜

### ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸
- **ì»¨íŠ¸ë¡¤ëŸ¬ë³„ API** ì‚¬ìš©ëŸ‰ ë° ì„±ëŠ¥
- **AppState ë©”ëª¨ë¦¬** ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§
- **ë¡œê·¸ ì‹œìŠ¤í…œ** ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
- **GitHub Actions** ë¹Œë“œ ì„±ê³µë¥ 
- **API ëª…ì„¸ì„œ** ìë™ ì—…ë°ì´íŠ¸ ìƒíƒœ

### ë¬¸ì œ í•´ê²°
- **ì»¨íŠ¸ë¡¤ëŸ¬ ë¼ìš°íŒ… ì‹¤íŒ¨**: ëª¨ë“ˆ ì„í¬íŠ¸ ê²½ë¡œ í™•ì¸
- **AppState ë©”ëª¨ë¦¬ ëˆ„ìˆ˜**: ëª¨ë¸ í•´ì œ ë¡œì§ í™•ì¸
- **GitHub Actions ì‹¤íŒ¨**: ê¶Œí•œ ë° ì‹œí¬ë¦¿ ì„¤ì • í™•ì¸
- **API ë¬¸ì„œ ë™ê¸°í™” ì‹¤íŒ¨**: OpenAPI ìŠ¤í‚¤ë§ˆ ê²€ì¦

### ì„±ëŠ¥ íŠœë‹
1. **ì»¨íŠ¸ë¡¤ëŸ¬ ìµœì í™”**
   - ë¹„ë™ê¸° ì²˜ë¦¬ í–¥ìƒ
   - ë©”ëª¨ë¦¬ í’€ë§ êµ¬í˜„
   - ìš”ì²­ í ê´€ë¦¬

2. **AppState ìµœì í™”**
   - ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìºì‹±
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
   - GC íŠœë‹ ì ìš©

3. **CI/CD ìµœì í™”**
   - ìºì‹± ì „ëµ êµ¬í˜„
   - ë³‘ë ¬ ë¹Œë“œ ì„¤ì •
   - ì¡°ê±´ë¶€ ì‹¤í–‰ ìµœì í™”

## ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### í™•ì¥ëœ ë³´ì•ˆ ê¸°ëŠ¥
- **ì»¨íŠ¸ë¡¤ëŸ¬ ë¶„ë¦¬**: ë¼ìš°í„°ë³„ ë…ë¦½ ë³´ì•ˆ ì •ì±…
- **AppState ë³´í˜¸**: ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë¬´ë‹¨ ì ‘ê·¼ ë°©ì§€
- **GitHub Secrets**: API í‚¤ ë° ë¯¼ê° ì •ë³´ ë³´í˜¸
- **ë¡œê·¸ ë³´ì•ˆ**: ê°œì¸ì •ë³´ ë¡œê¹… ë°©ì§€

### API ë³´ì•ˆ ê°•í™”
- **ì»¨íŠ¸ë¡¤ëŸ¬ ì ‘ê·¼ ì œì–´**: ê²½ë¡œë³„ ì¸ì¦ ë° ê²€ì¦
- **ì˜ˆì™¸ ì²˜ë¦¬ í†µí•©**: ë³´ì•ˆ ì·¨ì•½ì  ìµœì†Œí™”
- **ìë™ ë¬¸ì„œí™”**: ë¯¼ê° ì •ë³´ ë…¸ì¶œ ë°©ì§€
