> # v1.0.0

# ğŸ—‚ï¸ ì£¼ìš” íŒŒì¼ êµ¬ì¡°
```
ğŸ“¦src
 â”£ ğŸ“‚logs
 â”£ ğŸ“‚utils
 â”ƒ â”£ ğŸ“œAI_Llama_8B.py
 â”ƒ â”£ ğŸ“œError_handlers.py 
 â”ƒ â”— ğŸ“œModels.py
 â”£ ğŸ“œ.env
 â”— ğŸ“œserver.py
```

---

## ğŸ“„ AI_Llama_8B.py

### ğŸ“Œ ì£¼ìš” êµ¬ì„± ìš”ì†Œ
#### 1. í´ë˜ìŠ¤

|í´ë˜ìŠ¤ ëª…ì¹­|ì„¤ëª…|
|:-----:|:-----|
|`LlamaChatModel`|Llama ëª¨ë¸ì„ GPUì— í• ë‹¹í•˜ì—¬ ì§ˆì˜ì‘ë‹µ í•˜ë„ë¡ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤|

#### 2. í•¨ìˆ˜/ë©”ì„œë“œ

- `__init__`
    > í´ë˜ìŠ¤ ì´ˆê¸°í™” ë©”ì„œë“œ, Llama ëª¨ë¸ì˜ íŒŒì¼ ì£¼ì†Œì™€ ê° GPUì˜ ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”, í† í¬ë‚˜ì´ì €ì™€ GPUì˜ íŒŒì´í”„ë¼ì¸ ë¡œë“œ, ëª¨ë¸ì˜ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì¤€ë¹„í•˜ëŠ” ê³¼ì •ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì„œë“œ

    ```python
    def __init__(self):
        '''
        LlamaChatModel í´ë˜ìŠ¤ ì´ˆê¸°í™”
        '''
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(current_dir)
        dotenv_path = os.path.join(parent_dir, '.env')
        load_dotenv(dotenv_path)
        self.cache_dir = "./fastapi/ai_model/"
        self.model_id = "meta-llama/Llama-3.1-8B-Instruct"
        self.bart_model_id = "facebook/bart-large-mnli"
        self.model_kwargs = {
            "torch_dtype": torch.float16,
            "trust_remote_code": True,
            "quantization_config": BitsAndBytesConfig(load_in_4bit=True)
        }

        self.hf_token = os.getenv("HUGGING_FACE_TOKEN")
        self.accelerator = Accelerator(mixed_precision="fp16")
        self.device_2080 = torch.device("cuda:0")
        self.device_1050 = torch.device("cuda:1")

        print("í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘...")
        self.tokenizer = self.load_tokenizer()
        print("ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.model, self.optimizer = self.load_model_with_accelerator()
        print("ë³µì¡ë„ ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.complexity_analyzer = self.load_complexity_analyzer()
        self.scaler = GradScaler()
        print("ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ!")

        self.model.gradient_checkpointing_enable()
        self.conversation_history = []
    ```

- `load_tokenizer`
    > `transformers.AutoTokenizer`ì— Llama ëª¨ë¸(`self.model_id`)ì„ í• ë‹¹í•œ ë³€ìˆ˜(`tokenizer`)ë¥¼ ë°˜í™˜

    ```python
    def load_tokenizer(self) -> transformers.PreTrainedTokenizerBase:
        '''
        í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        :return: ë¡œë“œëœ í† í¬ë‚˜ì´ì €
        '''
        tokenizer = transformers.AutoTokenizer.from_pretrained(
            self.model_id,
            token=self.hf_token
        )
        tokenizer.pad_token_id = tokenizer.eos_token_id
        return tokenizer
    ```

- `load_complexity_analyzer`
    > ë³µì¡ë„ ë¶„ì„ ëª¨ë¸ì„ GTX 1050ì—ì„œ ë¡œë“œ, `pipeline`ì— `task="text-classification"`ë¥¼ í†µí•œ GPU 1050ì— ë³µì¡ë„ ë¶„ì„ìš©ìœ¼ë¡œ BART í• ë‹¹

    ```python
    def load_complexity_analyzer(self) -> transformers.Pipeline:
        '''
        ë³µì¡ë„ ë¶„ì„ ëª¨ë¸ì„ GTX 1050ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
        :return: ë¡œë“œëœ ë³µì¡ë„ ë¶„ì„ íŒŒì´í”„ë¼ì¸
        '''
        return pipeline(
            "text-classification",
            model=self.bart_model_id,
            device=self.device_1050.index,
        )
    ```
- `load_model_with_accelerator`
    > Llama ëª¨ë¸ì— ëŒ€í•œ ì˜µí‹°ë§ˆì´ì €ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ `transformers.AutoModelForCausalLM`ë¥¼ ì‚¬ìš©í•˜ì—¬ Llama ëª¨ë¸ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±, ëª¨ë¸ ì¸ì„œí„´ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ GPU 2080ì„ í• ë‹¹ ë° ì˜µí‹°ë§ˆì´ì €ë¥¼ ìƒì„± í›„ ëª¨ë¸ê³¼ ì˜µí‹°ë§ˆì´ì €ë¥¼ ë°˜í™˜

    ```python
    def load_model_with_accelerator(self) -> tuple:
        '''
        ëª¨ë¸ì„ Acceleratorë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œë“œí•˜ê³  ì˜µí‹°ë§ˆì´ì €ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
        :return: ëª¨ë¸ê³¼ ì˜µí‹°ë§ˆì´ì €
        '''
        model = transformers.AutoModelForCausalLM.from_pretrained(
            self.model_id,
            cache_dir=self.cache_dir,
            token=self.hf_token,
            **self.model_kwargs
        )
        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)
        model, optimizer = self.accelerator.prepare(model, optimizer)
        model.to(self.device_2080)
        return model, optimizer
    ```
- `analyze_complexity`
    > `input_text: str`ë¥¼ ë©”ê²Œë³€ìˆ˜ë¡œ ë°›ì•„ì™€ì„œ `load_complexity_analyzer`ë¥¼ í†µí•´ í• ë‹¹í•œ ì¸ìŠ¤í„´ìŠ¤ `self.complexity_analyzer`ì— ì „ë‹¬, ë¬¸ì¥ì˜ ë³µì¡ë„ë¥¼ ì „ë‹¬ ë°›ì•„ `low`,`medium`,`high`ë¥¼ ë°˜í™˜

    ```python
    def analyze_complexity(self, input_text: str) -> str:
        '''
        ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ë³µì¡ì„±ì„ GTX 1050ì—ì„œ ë¶„ì„í•©ë‹ˆë‹¤.
        :param input_text: ì…ë ¥ í…ìŠ¤íŠ¸
        :return: ë³µì¡ë„ ê²°ê³¼ (low, medium, high)
        '''
        result = self.complexity_analyzer(input_text)
        label = result[0]['label']
        if "ENTAILMENT" in label:
            return "low"
        elif "CONTRADICTION" in label:
            return "high"
        return "medium"
    ```
- `adjust_max_tokens`
    > `complexity: str`ë¥¼ ë©”ê²Œë³€ìˆ˜ë¡œ ë°˜ì•„ì™€ì„œ ê° ë³µì¡ë„ì— ë”°ë¥¸ í† í° ê°’ì„ `low = 100`, `medium = 250`, `high = 500`ìœ¼ë¡œ ë°˜í™˜
    ```python
    def adjust_max_tokens(self, complexity: str) -> int:
        '''
        ë³µì¡ë„ì— ë”°ë¼ ìƒì„±í•  ìµœëŒ€ í† í° ìˆ˜ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
        :param complexity: ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ë³µì¡ë„
        :return: ì¡°ì •ëœ ìµœëŒ€ í† í° ìˆ˜
        '''
        if complexity == "low":
            return 100 
        elif complexity == "high":
            return 500
        return 250
    ```
- `generate_response`
    > `input_text: str`ë¥¼ ë©”ê²Œë³€ìˆ˜ë¡œ ë°›ì•„ì™€ì„œ `analyze_complexity`, `adjust_max_tokens`ë¥¼ ê±°ì³ ìµœëŒ€ì¹˜ í† í° ê°’ì„ í• ë‹¹ ë°›ì€ ë’¤, í† í¬ë‚˜ì´ì €ë¡œ ì¸ì½”ë”©í•˜ì—¬ llama ëª¨ë¸ì— ì„¤ì • ê°’ë“¤ê³¼ í•¨ê»˜ ì „ì†¡, ë°›ì•„ì˜¨ ë¬¸ì¥ì„ ë””ì½”ë”©í•˜ì—¬ ë°˜í™˜í•œë‹¤.

    ```python
    def generate_response(self, input_text: str) -> str:
        '''
        ì£¼ì–´ì§„ ì…ë ¥ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
        :param input_text: ì…ë ¥ í…ìŠ¤íŠ¸
        :return: ìƒì„±ëœ ì‘ë‹µ í…ìŠ¤íŠ¸
        '''
        complexity = self.analyze_complexity(input_text)
        max_new_tokens = self.adjust_max_tokens(complexity)

        full_input = f"{input_text}"
        input_ids = self.tokenizer.encode(full_input, return_tensors="pt").to(torch.device("cpu"))
        attention_mask = (input_ids != self.tokenizer.pad_token_id).long()

        with autocast(dtype=torch.float16):
            with torch.no_grad():
                output = self.model.generate(
                    input_ids.to(self.device_2080),
                    attention_mask=attention_mask.to(self.device_2080),
                    max_new_tokens=max_new_tokens,
                    do_sample=True,
                    temperature=0.64,
                    top_k=51,
                    top_p=0.63,
                    eos_token_id=self.tokenizer.eos_token_id,
                    pad_token_id=self.tokenizer.eos_token_id,
                    repetition_penalty=1.21,
                )
        response = self.tokenizer.decode(output[0], skip_special_tokens=True)
        return response
    ```

---

## ğŸ“„ Error_handlers.py

### ğŸ“Œ ì£¼ìš” êµ¬ì„± ìš”ì†Œ
#### 1. í´ë˜ìŠ¤

|í´ë˜ìŠ¤ ëª…ì¹­|ì„¤ëª…|
|:-----:|:-----|
|`NotFoundException`|HTTP 404 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. ìš”ì²­í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ ë°œìƒ|
|`BadRequestException`|HTTP 400 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. í´ë¼ì´ì–¸íŠ¸ì˜ ì˜ëª»ëœ ìš”ì²­ìœ¼ë¡œ ì¸í•´ ë°œìƒ|
|`UnauthorizedException`|HTTP 401 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ìì˜ ì ‘ê·¼ ì‹œë„ ì‹œ ë°œìƒ|
|`ForbiddenException`|HTTP 403 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. ê¶Œí•œì´ ì—†ëŠ” ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì ‘ê·¼ ì‹œë„ ì‹œ ë°œìƒ|
|`ValueErrorException`|HTTP 422 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. ì…ë ¥ê°’ì˜ í˜•ì‹ì´ë‚˜ íƒ€ì…ì´ ì˜¬ë°”ë¥´ì§€ ì•Šì„ ë•Œ ë°œìƒ|
|`InternalServerErrorException`|HTTP 500 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. ì„œë²„ ë‚´ë¶€ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ë•Œ ì‚¬ìš©|
|`DatabaseErrorException`|HTTP 503 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë‚˜ ì¿¼ë¦¬ ì˜¤ë¥˜ ë“± DB ê´€ë ¨ ë¬¸ì œ ë°œìƒ ì‹œ ì‚¬ìš©|
|`IPRestrictedException`|HTTP 403 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. í—ˆìš©ë˜ì§€ ì•Šì€ IP ì£¼ì†Œì—ì„œì˜ ì ‘ê·¼ ì‹œë„ ì‹œ ë°œìƒ|
|`MethodNotAllowedException`|HTTP 405 ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ì˜ˆì™¸ í´ë˜ìŠ¤. ì§€ì›í•˜ì§€ ì•ŠëŠ” HTTP ë©”ì„œë“œë¡œ ìš”ì²­í–ˆì„ ë•Œ ë°œìƒ|