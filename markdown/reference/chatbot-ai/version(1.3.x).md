# ChatBot AI - ë²„ì „ ëª…ì„¸ì„œ v1.3.x

## ê°œìš”
ì´ ë¬¸ì„œëŠ” ChatBot AI ì‹œìŠ¤í…œì˜ v1.3.x ê³„ì—´ ë²„ì „ì— ëŒ€í•œ ê³µì‹ ëª…ì„¸ì„œì…ë‹ˆë‹¤. v1.2.xì˜ GGUF ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œì—ì„œ **ì™„ì „í•œ GGUF ê¸°ë°˜ ì•„í‚¤í…ì²˜**ë¡œ ì „í™˜ë˜ì—ˆìœ¼ë©°, **DuckDuckGo ê²€ìƒ‰ ì—°ë™**, **ëª¨ë“ˆí™”ëœ êµ¬ì¡°**, **JSON ì‘ë‹µ ì‹œìŠ¤í…œ**ì„ ë„ì…í•œ ì°¨ì„¸ëŒ€ AI ì±—ë´‡ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤.

## ë²„ì „ ì •ë³´

| ë²„ì „ | ë¦´ë¦¬ì¦ˆ ë‚ ì§œ | ì»¤ë°‹ í•´ì‹œ | ìƒíƒœ |
|------|-------------|-----------|------|
| **v1.3.0** | 2025-02-18 | `a1a8067b5175df55789daab8dcf250c95e6d2932` | Stable |
| **v1.3.1** | 2025-02-18 | `be178f1d87d1508284a425cb3094402804c593b0` | Latest |
| **None** | 2025-03-15 | `6d78b2bfcb9d13aad2766baa30acd684da81f973` | Unstable |

## v1.2.xì—ì„œ v1.3.xë¡œì˜ ì£¼ìš” ë³€ê²½ì‚¬í•­

### ì•„í‚¤í…ì²˜ í˜ì‹ 
- **Transformers + GGUF í•˜ì´ë¸Œë¦¬ë“œ** â†’ **ì™„ì „í•œ GGUF ê¸°ë°˜** ì‹œìŠ¤í…œ
- **Llama Transformers ëª¨ë¸ ì œê±°** â†’ **Bllossom GGUF ëª¨ë¸ ì¶”ê°€**
- **Lumimaid 8B** â†’ **3ê°œ GGUF ëª¨ë¸ ì§€ì›** (Llama, Lumimaid, Bllossom)

### ì¸í”„ë¼ ë³€í™”
- **MongoDB ì»¨í…Œì´ë„ˆ** â†’ **ë¡œì»¬ MongoDB ì—°ë™**
- **Docker ì˜ì¡´ì„± ì™„ì „ ì œê±°**
- **ëª¨ë“ˆí™”ëœ íŒ¨í‚¤ì§€ êµ¬ì¡°** ë„ì…

### ì‹ ê·œ ê¸°ëŠ¥
- **DuckDuckGo ê²€ìƒ‰ API** í†µí•© (Google ê²€ìƒ‰ ëŒ€ì²´)
- **JSON ì‘ë‹µ ì‹œìŠ¤í…œ** (SSE ìŠ¤íŠ¸ë¦¬ë°ê³¼ ë³‘í–‰)
- **ëŒ€í™” ê¸°ë¡ ê´€ë¦¬** (MongoDB ê¸°ë°˜)
- **ê¹Šì€ ë²ˆì—­ê¸°** (deep-translator) ì§€ì›
- **í–¥ìƒëœ ì—ëŸ¬ ì²˜ë¦¬** ë° ë¡œê¹… ì‹œìŠ¤í…œ

### ì œê±°ëœ ê¸°ëŠ¥
- âŒ **Transformers ê¸°ë°˜ Llama ëª¨ë¸**
- âŒ **Google Search API** ì—°ë™
- âŒ **Docker ì»¨í…Œì´ë„ˆ** í™˜ê²½
- âŒ **MongoDB ë¼ìš°í„°** ë…ë¦½ ì—”ë“œí¬ì¸íŠ¸

## ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­
- **GPU**: NVIDIA RTX 3060 (CUDA:0) + RTX 2080 (CUDA:1)
- **VRAM**: ìµœì†Œ 20GB RAM (3060 12GB + 2080 8GB)
- **ì €ì¥ê³µê°„**: ìµœì†Œ 50GB ì—¬ìœ  ê³µê°„

### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­
- **ìš´ì˜ì²´ì²´**: Windows 10/11 (64-bit)
- **Python**: 3.11 ì´ìƒ
- **CUDA**: 11.8/12.8 ì§€ì›
- **llama-cpp-python**: CUDA ì§€ì› ë²„ì „
- **MongoDB**: ë¡œì»¬ ì„¤ì¹˜

## ì•„í‚¤í…ì²˜

### í”„ë¡œì íŠ¸ êµ¬ì¡°
```
ğŸ“¦ ChatBot AI v1.3.x
â”œâ”€â”€ ğŸ“ fastapi/
â”‚   â”œâ”€â”€ ğŸ“ ai_model/              # GGUF ëª¨ë¸ ì €ì¥ì†Œ
â”‚   â”‚   â”œâ”€â”€ llama-3-Korean-Bllossom-8B-gguf-Q4_K_M.gguf [NEW]
â”‚   â”‚   â”œâ”€â”€ v2-Llama-3-Lumimaid-8B-v0.1-OAS-Q5_K_S-imat.gguf
â”‚   â”‚   â””â”€â”€ README.md [UPDATED]
â”‚   â”œâ”€â”€ ğŸ“ src/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ utils/             # ëª¨ë“ˆí™”ëœ ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ ai_models/     # AI ëª¨ë¸ ëª¨ë“ˆ [NEW]
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ bllossom_model.py [NEW]
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lumimaid_model.py [RENAMED]
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ llama_model.py [RENAMED]
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ handlers/      # í•¸ë“¤ëŸ¬ ëª¨ë“ˆ [NEW]
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ error_handler.py [NEW]
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ language_handler.py [NEW]
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mongodb_handler.py [NEW]
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ schemas/       # ìŠ¤í‚¤ë§ˆ ëª¨ë“ˆ [NEW]
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ chat_schema.py [NEW]
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ services/      # ì„œë¹„ìŠ¤ ëª¨ë“ˆ [NEW]
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ search_service.py [NEW]
â”‚   â”‚   â”‚   â””â”€â”€ __init__.py [UPDATED]
â”‚   â”‚   â”œâ”€â”€ server.py [UPDATED]
â”‚   â”‚   â”œâ”€â”€ bot.yaml
â”‚   â”‚   â””â”€â”€ index.html [UPDATED]
â”‚   â”œâ”€â”€ requirements_llama.txt    # llama.cpp ê´€ë ¨ íŒ¨í‚¤ì§€
â”‚   â””â”€â”€ requirements.txt [UPDATED]
â”œâ”€â”€ ğŸ“ models/                    # ëª¨ë¸ ì„¤ì • íŒŒì¼ [NEW]
â”‚   â””â”€â”€ config-Bllossom.json [NEW]
â””â”€â”€ .env
```

## API ëª…ì„¸

### ì—”ë“œí¬ì¸íŠ¸

#### POST /office_stream
Bllossom ëª¨ë¸ ê¸°ë°˜ DuckDuckGo ê²€ìƒ‰ ì—°ë™ JSON ì‘ë‹µ

**ìš”ì²­ í˜•ì‹:**
```json
{
  "input_data": "string (1-500ì)",
  "google_access": "boolean (default: false)",
  "db_id": "string (UUID)",
  "user_id": "string"
}
```

**ì‘ë‹µ í˜•ì‹:**
- **Content-Type**: `application/json`
- **Response**: `{"response": "string"}`

#### POST /character_stream
Lumimaid ëª¨ë¸ ê¸°ë°˜ ìºë¦­í„° ëŒ€í™” JSON ì‘ë‹µ

**ìš”ì²­ í˜•ì‹:**
```json
{
  "input_data": "string (1-500ì)",
  "character_name": "string",
  "greeting": "string",
  "context": "string",
  "db_id": "string (UUID)",
  "user_id": "string"
}
```

**ì˜ˆì‹œ ìš”ì²­:**
```json
{
  "input_data": "*I approach Rachel and talk to her.*",
  "character_name": "Rachel",
  "greeting": "*Rachel stands nervously at the lectern...*",
  "context": "Rachel is a devout Catholic girl...",
  "db_id": "b440780c-cbaa-454f-a8d2-cf884786d89f",
  "user_id": "djjdjs74"
}
```

#### SSE ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸

##### POST /office_sse
Bllossom ëª¨ë¸ SSE ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

##### POST /character_sse
Lumimaid ëª¨ë¸ SSE ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ

**HTTP ìƒíƒœ ì½”ë“œ:**
- `200`: ì„±ê³µ
- `400`: ì˜ëª»ëœ ìš”ì²­
- `422`: ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨
- `500`: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜

## ì£¼ìš” ì»´í¬ë„ŒíŠ¸

### 1. ì„œë²„ ì»´í¬ë„ŒíŠ¸ (server.py) - v1.3.x ì™„ì „ ì¬ì„¤ê³„

#### ì™„ì „í•œ GGUF ê¸°ë°˜ ì•„í‚¤í…ì²˜
v1.2.xì˜ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œì—ì„œ **ìˆœìˆ˜ GGUF ê¸°ë°˜**ìœ¼ë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.

```python
@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    FastAPI AI ëª¨ë¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì´ˆê¸°í™” - v1.3.x
    ì™„ì „í•œ GGUF ê¸°ë°˜ ì‹œìŠ¤í…œ (Bllossom + Lumimaid)
    """
    global Bllossom_model, Lumimaid_model, GREEN, RESET

    def get_cuda_device_info(device_id: int) -> str:
        device_name = torch.cuda.get_device_name(device_id)
        device_properties = torch.cuda.get_device_properties(device_id)
        total_memory = device_properties.total_memory / (1024 ** 3)
        return f"Device {device_id}: {device_name} (Total Memory: {total_memory:.2f} GB)"

    try:
        # ì™„ì „í•œ GGUF ëª¨ë¸ ì‹œìŠ¤í…œ
        Bllossom_model = Bllossom()  # cuda:1 (RTX 2080)
        Lumimaid_model = Lumimaid()  # cuda:0 (RTX 3060)
    except ChatError.InternalServerErrorException as e:
        print(f"{RED}ERROR{RESET}: ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        exit(1)
        
    # ë””ë²„ê¹…ìš© ì¶œë ¥
    Bllossom_device_info = get_cuda_device_info(1)
    Lumimaid_device_info = get_cuda_device_info(0)
    print(f"{GREEN}INFO{RESET}: Bllossom ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({Bllossom_device_info})")
    print(f"{GREEN}INFO{RESET}: Lumimaid ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({Lumimaid_device_info})")

    yield

    Bllossom_model = None
    Lumimaid_model = None
    print(f"{GREEN}INFO{RESET}: ëª¨ë¸ í•´ì œ ì™„ë£Œ")
```

#### JSON ì‘ë‹µ ì‹œìŠ¤í…œ
ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹  JSON ì‘ë‹µì„ ê¸°ë³¸ìœ¼ë¡œ í•˜ëŠ” ìƒˆë¡œìš´ API êµ¬ì¡°ì…ë‹ˆë‹¤.

```python
@app.post("/office_stream", summary="AI ëª¨ë¸ì´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ Bllossom ëª¨ë¸ ë‹µë³€ ìƒì„±")
async def office_stream(request: ChatModel.Bllossom_Request):
    """
    Bllossom_8B ëª¨ë¸ì— ì§ˆë¬¸ì„ DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ì™€ ê²°í•©í•˜ì—¬ JSON ì‘ë‹µìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        chat_list = await mongo_handler.get_office_log(
            user_id=request.user_id,
            document_id=request.db_id,
            router="office",
        )
        search_context = ""
        
        # DuckDuckGo ê²€ìƒ‰ ì—°ë™
        if request.google_access:
            try:
                duck_results = await ChatSearch.fetch_duck_search_results(query=request.input_data)
                
                if duck_results:
                    formatted_results = []
                    for idx, item in enumerate(duck_results[:10], 1):
                        formatted_result = (
                            f"[ê²€ìƒ‰ê²°ê³¼ {idx}]\n"
                            f"ì œëª©: {item.get('title', 'ì œëª© ì—†ìŒ')}\n"
                            f"ë‚´ìš©: {item.get('snippet', 'ë‚´ìš© ì—†ìŒ')}\n"
                            f"ì¶œì²˜: {item.get('link', 'ë§í¬ ì—†ìŒ')}\n"
                        )
                        formatted_results.append(formatted_result)
                    
                    search_context = (
                        "ë‹¤ìŒì€ ê²€ìƒ‰ì—ì„œ ê°€ì ¸ì˜¨ ê´€ë ¨ ì •ë³´ì…ë‹ˆë‹¤:\n\n" +
                        "\n".join(formatted_results)
                    )
            except Exception:
                print(f"{RED}ERROR{RESET}: DuckDuckGo ê²€ìƒ‰ ì‹¤íŒ¨")
                search_context = ""
                
        # JSON ì‘ë‹µ ìƒì„±
        full_response = ""
        for chunk in Bllossom_model.generate_response_stream(
            input_text=request.input_data,
            search_text=search_context,
            chat_list=chat_list,
        ):
            full_response += chunk
            
        return full_response
    
    except Exception as e:
        raise ChatError.InternalServerErrorException(detail="ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
```

### 2. AI ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ - v1.3.x ëª¨ë“ˆí™”

#### BllossomChatModel í´ë˜ìŠ¤ (bllossom_model.py) - ì‹ ê·œ ì¶”ê°€

**ì£¼ìš” íŠ¹ì§•:**
- **ëª¨ë¸**: `llama-3-Korean-Bllossom-8B-gguf-Q4_K_M.gguf`
- **ì—”ì§„**: llama-cpp-cuda (CUDA ì§€ì›)
- **GPU**: CUDA:1 (RTX 2080) ì „ìš©
- **ì–‘ìí™”**: Q4_K_M (ê³ íš¨ìœ¨ 4-bit ì–‘ìí™”)
- **ê²€ìƒ‰ ì—°ë™**: DuckDuckGo ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬

```python
class BllossomChatModel:
    """
    GGUF í¬ë§·ìœ¼ë¡œ ê²½ëŸ‰í™”ëœ Llama-3-Bllossom-8B ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , 
    ì£¼ì–´ì§„ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    """
    def __init__(self) -> None:
        """
        GGUF ëª¨ë¸ ì´ˆê¸°í™” - RTX 2080 ìµœì í™”
        """
        self.model_path = "fastapi/ai_model/llama-3-Korean-Bllossom-8B-gguf-Q4_K_M.gguf"
        self.verbose = False
        self.gpu_layers = 50
        self.model = self._load_model()
        self.response_queue = Queue()

    def _load_model(self) -> Llama:
        """
        Llama ëª¨ë¸ì„ CUDA:1 ë””ë°”ì´ìŠ¤(RTX 2080)ì— ë¡œë“œ
        """
        print("GGUF Bllossom ëª¨ë¸ ë¡œë“œ ì¤‘...")
        try:
            model = Llama(
                model_path=self.model_path,
                n_gpu_layers=self.gpu_layers,
                main_gpu=1,                # RTX 2080 ì‚¬ìš©
                n_ctx=4096,                # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì¦ê°€
                n_batch=512,
                verbose=self.verbose,
                offload_kqv=True,
                use_mmap=False,
                use_mlock=True,
                n_threads=8
            )
            print("âœ… GGUF Bllossom ëª¨ë¸ì´ CUDA:1 (RTX 2080)ì— ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return model
        except Exception as e:
            print(f"âŒ GGUF Bllossom ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
```

#### LumimaidChatModel í´ë˜ìŠ¤ (lumimaid_model.py) - v1.3.x ì—…ë°ì´íŠ¸

**v1.2.xì—ì„œ ë³€ê²½ëœ ì‚¬í•­:**
- âœ… **GPU í• ë‹¹ ë³€ê²½** (CUDA:1 â†’ CUDA:0)
- âœ… **ëŒ€í™” ê¸°ë¡ ê´€ë¦¬** í†µí•©
- âœ… **ëª¨ë“ˆí™”ëœ êµ¬ì¡°** ì ìš©

```python
def generate_response_stream(self, input_text: str, character_settings: dict = None, chat_list: List[Dict] = None) -> Generator[str, None, None]:
    """
    ìºë¦­í„° ì„¤ì •ê³¼ ëŒ€í™” ê¸°ë¡ì„ ë°˜ì˜í•œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± - v1.3.x
    
    Args:
        input_text (str): ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
        character_settings (dict): ìºë¦­í„° ì„¤ì • ë”•ì…”ë„ˆë¦¬
        chat_list (List[Dict]): ì´ì „ ëŒ€í™” ê¸°ë¡
        
    Yields:
        str: ìƒì„±ëœ í…ìŠ¤íŠ¸ ì¡°ê°ë“¤
    """
    try:
        # ìºë¦­í„° ì •ë³´ ë° ëŒ€í™” ê¸°ë¡ ì„¤ì •
        if character_settings:
            character_info = CharacterPrompt(
                name=character_settings.get("character_name", "Assistant"),
                context=character_settings.get("context", ""),
                search_text=""
            )
            # Llama3 messages í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ëŒ€í™” ê¸°ë¡ í¬í•¨)
            messages = build_llama3_messages(character_info, input_text, chat_list)
        else:
            messages = [{"role": "user", "content": input_text}]
        
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        for text_chunk in self.create_streaming_completion(
            messages=messages,
            max_tokens=2048,
            temperature=0.7,
            top_p=0.95,
            stop=["<|eot_id|>"]
        ):
            yield text_chunk

    except Exception as e:
        print(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        yield f"ì˜¤ë¥˜: {str(e)}"
```

### 3. ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì»´í¬ë„ŒíŠ¸ (search_service.py) - ì‹ ê·œ ì¶”ê°€

#### DuckDuckGo ê²€ìƒ‰ ì—°ë™
Google Search APIë¥¼ ëŒ€ì²´í•˜ëŠ” DuckDuckGo ê²€ìƒ‰ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

**ì£¼ìš” íŠ¹ì§•:**
- **ë¼ì´ë¸ŒëŸ¬ë¦¬**: langchain-community
- **ê²€ìƒ‰ ì—”ì§„**: DuckDuckGo API
- **í•„í„°ë§**: ë„ë©”ì¸ë³„ ê²°ê³¼ ë¶„ë¥˜
- **ì œí•œ ì—†ìŒ**: API í‚¤ ë¶ˆí•„ìš”

```python
async def fetch_duck_search_results(query: str) -> list:
    """
    DuckDuckGoë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        query (str): ê²€ìƒ‰ì–´
        
    Returns:
        list: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ì œëª©, ë‚´ìš©, ë§í¬ í¬í•¨)
        
    Raises:
        Exception: ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
    """
    try:
        # ê²€ìƒ‰ ë˜í¼ ì„¤ì •
        wrapper = DuckDuckGoSearchAPIWrapper(
            region="kr-kr",
            safesearch="moderate",
            max_results=50,
            time="y",  # 1ë…„ ì´ë‚´ ê²°ê³¼
            backend="auto"
        )
        
        # ê²€ìƒ‰ ë„êµ¬ ì„¤ì •
        search = DuckDuckGoSearchResults(
            api_wrapper=wrapper,
            num_results=20,
            output_format="json",
            backend="text"
        )
        
        # ê²€ìƒ‰ ìˆ˜í–‰
        result = search.invoke(query)
        search_results = json.loads(result)
        
        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for item in search_results:
            formatted_results.append({
                "title": item.get('title', 'N/A'),
                "snippet": item.get('snippet', 'N/A'),
                "link": item.get('link', 'N/A')
            })
            
        return formatted_results
        
    except Exception as e:
        print(f"{RED}ERROR{RESET}: DuckDuckGo ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
```

### 4. ë°ì´í„°ë² ì´ìŠ¤ ì»´í¬ë„ŒíŠ¸ (mongodb_handler.py) - v1.3.x í™•ì¥

#### ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ì‹œìŠ¤í…œ
MongoDB ê¸°ë°˜ì˜ ëŒ€í™” ê¸°ë¡ ì €ì¥ ë° ê²€ìƒ‰ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

```python
async def get_office_log(self, user_id: str, document_id: str, router: str) -> List[Dict]:
    """
    Office ë¼ìš°í„°ì˜ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        user_id (str): ì‚¬ìš©ì ID
        document_id (str): ë¬¸ì„œ ID
        router (str): ë¼ìš°í„° íƒ€ì…
        
    Returns:
        List[Dict]: ëŒ€í™” ê¸°ë¡ ë¦¬ìŠ¤íŠ¸
    """
    try:
        collection = self.db["chat_logs"]
        
        # ìµœê·¼ 10ê°œ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
        cursor = collection.find({
            "user_id": user_id,
            "document_id": document_id,
            "router": router
        }).sort("timestamp", -1).limit(10)
        
        chat_logs = await cursor.to_list(length=10)
        
        # ì‹œê°„ìˆœ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
        chat_logs.reverse()
        
        return chat_logs
        
    except Exception as e:
        print(f"{self.RED}ERROR{self.RESET}: ëŒ€í™” ê¸°ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

async def get_character_log(self, user_id: str, document_id: str, router: str) -> List[Dict]:
    """
    Character ë¼ìš°í„°ì˜ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    # office_logì™€ ë™ì¼í•œ ë¡œì§
    return await self.get_office_log(user_id, document_id, router)
```

### 5. ë°ì´í„° ëª¨ë¸ ì»´í¬ë„ŒíŠ¸ (chat_schema.py) - v1.3.x ê°„ì†Œí™”

#### í†µí•©ëœ ìš”ì²­/ì‘ë‹µ ëª¨ë¸
v1.2.xì˜ ë³µì¡í•œ ëª¨ë¸ êµ¬ì¡°ë¥¼ ê°„ì†Œí™”í•˜ê³  í†µí•©í–ˆìŠµë‹ˆë‹¤.

**ì‹ ê·œ í•„ë“œ:**
- âœ… `db_id` (ë°ì´í„°ë² ì´ìŠ¤ ë¬¸ì„œ ID)
- âœ… `user_id` (ì‚¬ìš©ì ì‹ë³„ì)

**ì œê±°ëœ í•„ë“œ:**
- âŒ `image` (ìºë¦­í„° ì´ë¯¸ì§€ URL ì œê±°)
- âŒ `access_level` (ì ‘ê·¼ ê¶Œí•œ ë‹¨ìˆœí™”)

```python
class Bllossom_Request(BaseModel):
    """
    Bllossom ëª¨ë¸ API ìš”ì²­ - v1.3.x ì—…ë°ì´íŠ¸
    DuckDuckGo ê²€ìƒ‰ê³¼ ëŒ€í™” ê¸°ë¡ì„ ì§€ì›í•˜ëŠ” ìš”ì²­ ëª¨ë¸
    """
    input_data: str = Bllossom_input_data_set
    google_access: bool = google_access_set
    db_id: str | None = db_id_set
    user_id: str | None = user_id_set

class Lumimaid_Request(BaseModel):
    """
    Lumimaid ëª¨ë¸ API ìš”ì²­ - v1.3.x ì—…ë°ì´íŠ¸
    ìºë¦­í„° ê¸°ë°˜ ëŒ€í™”ì™€ ëŒ€í™” ê¸°ë¡ì„ ì§€ì›í•˜ëŠ” ìš”ì²­ ëª¨ë¸
    """
    input_data: str = Lumimaid_input_data_set
    character_name: str = character_name_set
    greeting: str = greeting_set
    context: str = context_set
    db_id: str | None = db_id_set
    user_id: str | None = user_id_set
```

## ì„¤ì¹˜ ë° ì„¤ì •

### í™˜ê²½ ì„¤ì • ì‹œìŠ¤í…œ - v1.3.x ê°œì„ 

#### í†µí•©ëœ í™˜ê²½ êµ¬ì„±
Windows í™˜ê²½ì—ì„œ CUDA 11.8ê³¼ 12.8ì„ ë™ì‹œ ì§€ì›í•˜ëŠ” ê°œì„ ëœ ì„¤ì¹˜ ê°€ì´ë“œì…ë‹ˆë‹¤.

**CUDA í™˜ê²½ ì„¤ì •:**
- **CUDA 11.8**: PyTorch ë° ê¸°ë³¸ ëª¨ë¸ìš©
- **CUDA 12.8**: llama-cpp-python ìµœì í™”ìš©

**í•„ìˆ˜ íŒ¨í‚¤ì§€:**
```bash
# ê¸°ë³¸ íŒ¨í‚¤ì§€
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# GGUF ì§€ì›
pip install llama-cpp-python[cuda]

# ê²€ìƒ‰ ë° ë²ˆì—­
pip install duckduckgo-search langchain-community deep-translator

# ìì—°ì–´ ì²˜ë¦¬
pip install spacy sentence-transformers
```

### ë¡œì»¬ MongoDB ì„¤ì •
Docker ì˜ì¡´ì„±ì„ ì œê±°í•˜ê³  ë¡œì»¬ MongoDB ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.

```yaml
# MongoDB ì„¤ì • ì˜ˆì‹œ
database:
  host: localhost
  port: 27017
  name: chatbot_db
  collections:
    - chat_logs
    - user_profiles
    - character_configs
```

## ì„±ëŠ¥ íŠ¹ì„±

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **Bllossom (GGUF)**: ~8GB VRAM (RTX 2080)
- **Lumimaid (GGUF)**: ~6GB VRAM (RTX 3060)
- **MongoDB**: ~512MB RAM
- **ì‹œìŠ¤í…œ RAM**: ~6-8GB

### ì²˜ë¦¬ëŸ‰
- **ë™ì‹œ ìš”ì²­**: 2ê°œ (ì™„ì „í•œ GGUF ë¶„ì‚° ì²˜ë¦¬)
- **ì‹œê°„ë‹¹ ìš”ì²­**: ~400-600ê°œ
- **GGUF ì„±ëŠ¥**: v1.2.x ëŒ€ë¹„ 15-25% í–¥ìƒ
- **JSON ì‘ë‹µ**: ìŠ¤íŠ¸ë¦¬ë° ëŒ€ë¹„ 30% ë¹ ë¥¸ ì‘ë‹µ

## ìš´ì˜ ê°€ì´ë“œ

### í™˜ê²½ ì„¤ì •
1. **Windows 11** + **Python 3.11** í™˜ê²½ êµ¬ì„±
2. **CUDA 11.8/12.8** ë“œë¼ì´ë²„ ì„¤ì¹˜
3. **ë¡œì»¬ MongoDB** ì„¤ì¹˜ ë° êµ¬ì„±
4. **GGUF ëª¨ë¸** ë‹¤ìš´ë¡œë“œ ë° ë°°ì¹˜

### ë¬¸ì œ í•´ê²°
- **GGUF ë¡œë”© ì‹¤íŒ¨**: GPU ë©”ëª¨ë¦¬ í• ë‹¹ í™•ì¸
- **DuckDuckGo ê²€ìƒ‰ ì‹¤íŒ¨**: ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë° ì†ë„ ì œí•œ í™•ì¸
- **MongoDB ì—°ê²° ì˜¤ë¥˜**: ë¡œì»¬ MongoDB ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
- **ëŒ€í™” ê¸°ë¡ ì†ì‹¤**: ì»¬ë ‰ì…˜ ì¸ë±ìŠ¤ ë° ê¶Œí•œ í™•ì¸

### ì„±ëŠ¥ íŠœë‹
1. **GGUF íŒŒë¼ë¯¸í„°** ìµœì í™”
   - `n_gpu_layers`: 50 (Bllossom) / 35 (Lumimaid)
   - `n_ctx`: 4096 (ê¸´ ëŒ€í™” ì§€ì›)
   - `n_batch`: 512 â†’ 1024 (ì²˜ë¦¬ëŸ‰ í–¥ìƒ)

2. **MongoDB ìµœì í™”**
   - ëŒ€í™” ê¸°ë¡ TTL ì¸ë±ìŠ¤ ì„¤ì •
   - ì‚¬ìš©ìë³„ ìƒ¤ë”© êµ¬ì„±
   - ìºì‹œ í¬ê¸° ì¡°ì •

3. **ê²€ìƒ‰ ì‹œìŠ¤í…œ ìµœì í™”**
   - DuckDuckGo ê²°ê³¼ ìºì‹±
   - ê²€ìƒ‰ì–´ ì „ì²˜ë¦¬ ë° í•„í„°ë§
   - ê²°ê³¼ ìˆ˜ ì œí•œ (10-20ê°œ)

## ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### í™•ì¥ëœ ë³´ì•ˆ ê¸°ëŠ¥
- **ë¡œì»¬ MongoDB**: ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬
- **GGUF ëª¨ë¸ ê²€ì¦**: íŒŒì¼ ë¬´ê²°ì„± í™•ì¸
- **DuckDuckGo ì œí•œ**: ê²€ìƒ‰ ì¿¼ë¦¬ í•„í„°ë§

### API ë³´ì•ˆ ê°•í™”
- **ì‚¬ìš©ì ì¸ì¦**: user_id ê¸°ë°˜ ì ‘ê·¼ ì œì–´
- **ëŒ€í™” ê¸°ë¡ ë³´í˜¸**: ì‚¬ìš©ìë³„ ê²©ë¦¬
- **ê²€ìƒ‰ ì œí•œ**: ì•…ì„± ì¿¼ë¦¬ ë°©ì§€
- **JSON ì‘ë‹µ**: XSS ë° ì¸ì ì…˜ ë°©ì§€

## ë²„ì „ í˜¸í™˜ì„±

### v1.2.xì™€ì˜ ì°¨ì´ì 

| ê¸°ëŠ¥ | v1.2.x | v1.3.x |
|------|--------|--------|
| **ëª¨ë¸ ì•„í‚¤í…ì²˜** | Transformers + GGUF | ì™„ì „í•œ GGUF |
| **ê²€ìƒ‰ ì—”ì§„** | Google Search API | DuckDuckGo |
| **ì‘ë‹µ í˜•ì‹** | ìŠ¤íŠ¸ë¦¬ë° ì „ìš© | JSON + SSE |
| **ëŒ€í™” ê¸°ë¡** | âŒ ì—†ìŒ | âœ… MongoDB ê¸°ë°˜ |
| **ëª¨ë“ˆ êµ¬ì¡°** | ë‹¨ì¼ íŒŒì¼ | ëª¨ë“ˆí™”ëœ íŒ¨í‚¤ì§€ |
| **ë²ˆì—­ ì‹œìŠ¤í…œ** | googletrans | deep-translator |
| **í™˜ê²½** | ë¡œì»¬ + Docker | ì™„ì „í•œ ë¡œì»¬ |

## ë¼ì´ì„ ìŠ¤
ì´ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ë‹¤ìŒ ë¼ì´ì„ ìŠ¤ë¥¼ ì¤€ìˆ˜í•©ë‹ˆë‹¤:
- **Meta Llama 3.1**: Metaì˜ Llama ëª¨ë¸ ë¼ì´ì„ ìŠ¤
- **Lumimaid 8B**: Lewdiculous ëª¨ë¸ ë¼ì´ì„ ìŠ¤
- **Korean Bllossom 8B**: MLP-KTLim ëª¨ë¸ ë¼ì´ì„ ìŠ¤
- **llama.cpp**: MIT ë¼ì´ì„ ìŠ¤
- **DuckDuckGo**: ê³µê°œ ê²€ìƒ‰ API